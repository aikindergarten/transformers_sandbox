{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! TO MODIFY default_exp something_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from fastai.basics import *\n",
    "\n",
    "from functools import partial, reduce\n",
    "from inspect import isfunction\n",
    "from operator import mul\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "from transformers_sandbox.core import *\n",
    "from transformers_sandbox.layers import *\n",
    "#TODO\n",
    "#from transformers_sandbox.attention_core import *\n",
    "from transformers_sandbox.attention import *\n",
    "\n",
    "from torch.utils.checkpoint import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Module Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AttnInProj(Module):\n",
    "    \"\"\"Computes q, k, v from input x and [optional] context\"\"\"\n",
    "    def __init__(self, d_model:int, bias:bool=False):\n",
    "        self.to_q = nn.Linear(d_model, d_model, bias=bias)\n",
    "        self.to_k = nn.Linear(d_model, d_model, bias=bias)\n",
    "        self.to_v = nn.Linear(d_model, d_model, bias=bias)\n",
    "    def forward(self, x, context=None):\n",
    "        context = ifnone(context, x)\n",
    "        q = self.to_q(x)\n",
    "        k, v = self.to_k(context), self.to_v(context)\n",
    "        return q, k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 128, 64]), torch.Size([4, 128, 64]), torch.Size([4, 128, 64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "sl = 128\n",
    "d = 64\n",
    "x = torch.randn(bs, sl, d)\n",
    "context = torch.randn(bs, sl-16, d)\n",
    "proj = AttnInProj(d)\n",
    "q1, k1, v1 = proj(x)\n",
    "assert (bs, sl, d) == q1.size() == k1.size() == v1.size()\n",
    "q1.shape, k1.shape, v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 128, 64]), torch.Size([4, 112, 64]), torch.Size([4, 112, 64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2, k2, v2 = proj(x, context)\n",
    "assert (bs, sl, d) == q2.size()\n",
    "assert k2.size() == v2.size() == context.size()\n",
    "assert all_equal(q1, q2)\n",
    "assert not all_equal(k1, k2)\n",
    "q2.shape, k2.shape, v2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO make sure store_attention works\n",
    "class ScaledDotProdAttention(Module):\n",
    "    \"\"\"\n",
    "    Computes scaled dot-product attnetion given q, k, v\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, causal=False, dropout=0., shared_qk=False, store_attention:bool=False):\n",
    "        store_attr()\n",
    "        self.scale = (d_model//n_heads)**-0.5\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, q, k, v, attn_mask=None):\n",
    "        n, device = q.size(1), q.device\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.n_heads), (q, k, v))\n",
    "        \n",
    "        # classic dot-product attention\n",
    "        dots = torch.einsum('bhid,bhjd->bhij', q*self.scale, k)\n",
    "        \n",
    "        if exists(attn_mask):\n",
    "            dots.masked_fill_(~attn_mask, MASK_VAL)\n",
    "            del attn_mask            \n",
    "        if self.shared_qk:\n",
    "            m = torch.arange(n)   \n",
    "            dots[:, :, m, m] = SELF_ATTN_MASK_VAL\n",
    "        if self.causal:\n",
    "            i, j = torch.triu_indices(n, n, 1)\n",
    "            dots[:,:,i,j] = MASK_VAL\n",
    "\n",
    "        attn = F.softmax(dots, -1)\n",
    "        if self.store_attention: self.attention = attn.detach().cpu()\n",
    "        \n",
    "        attn = self.dropout(attn)\n",
    "        out = torch.einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled dot-product attention is calculated as:\n",
    "\n",
    "$$\\textbf {Attention}(Q,K,V) = \\textbf {softmax}({QK^T\\over\\sqrt d_k})V $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.randn(bs, sl, d)\n",
    "k = torch.randn(bs, sl, d)\n",
    "v = torch.randn(bs, sl, d)\n",
    "attn_func = ScaledDotProdAttention(d, 4)\n",
    "out = attn_func(q, k, v)\n",
    "assert out.size() == (bs,sl,d)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test shared_qk\n",
    "attn_func = ScaledDotProdAttention(d, 4, shared_qk=True)\n",
    "out = attn_func(q, k, v)\n",
    "assert out.size() == (bs,sl,d)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "attn_func = ScaledDotProdAttention(d, 4)\n",
    "mask = torch.ones(1,sl,sl).bool()\n",
    "out = attn_func(q, k, v, attn_mask=mask)\n",
    "assert out.size() == (bs,sl,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuda\n",
    "q = torch.randn(bs, sl, d).cuda()\n",
    "k = torch.randn(bs, sl, d).cuda()\n",
    "v = torch.randn(bs, sl, d).cuda()\n",
    "attn_func = ScaledDotProdAttention(d, 4, shared_qk=True)\n",
    "out = attn_func(q, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Attention(Module):\n",
    "    \"\"\"\n",
    "    Standard attention module using scaled dot-product attention\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 d_model:int, \n",
    "                 n_heads:int = 8, \n",
    "                 causal:bool = False,\n",
    "                 mask:Tensor = None,\n",
    "                 dropout:float=0.1,\n",
    "                 out_dropout:float=None,\n",
    "                 bias:bool=False,\n",
    "                 shared_qk:bool=False,\n",
    "                 store_attention:bool=False):\n",
    "        store_attr('causal, mask, n_heads, bias, shared_qk')\n",
    "        out_dropout = ifnone(out_dropout, dropout)\n",
    "        if shared_qk: self.in_proj = SharedQKAttnInProj(d_model, bias=bias)\n",
    "        else: self.in_proj = AttnInProjV2(d_model, bias=bias)\n",
    "        self.attn = ScaledDotProdAttention(d_model, n_heads, causal=causal,\n",
    "                                           dropout=dropout, shared_qk=shared_qk, \n",
    "                                           store_attention=store_attention)\n",
    "        self.out_proj = nn.Linear(d_model, d_model, bias=bias)\n",
    "        self.dropout = nn.Dropout(out_dropout)\n",
    "        self._init()\n",
    "\n",
    "    def forward(self, x, context = None, mask = None, context_mask = None):\n",
    "        q, k, v = self.in_proj(x, context)\n",
    "        if self.shared_qk: k = F.normalize(k, 2, dim=-1).type_as(k)\n",
    "                \n",
    "        attn_mask = self._make_attn_mask(mask, context_mask, x, context)\n",
    "        out = self.attn(q, k, v, attn_mask)\n",
    "        \n",
    "        out = self.out_proj(out)\n",
    "        return self.dropout(out)\n",
    "        \n",
    "    def _init(self):\n",
    "        [nn.init.xavier_uniform_(w) for w in self.parameters() if w.dim()>1]\n",
    "        if self.bias:\n",
    "            [nn.init.constant_(b, 0) for b in self.parameters() if b.dim()==1]\n",
    "    \n",
    "    def _make_attn_mask(self, mask, context_mask, x, context):\n",
    "        if any(map(exists, (mask, context_mask))):\n",
    "            b, n, _, device = *x.size(), x.device\n",
    "            q_mask = default(mask, lambda: torch.ones((b, n), device = device).bool())\n",
    "            k_mask = q_mask if not exists(context) else context_mask\n",
    "            k_mask = default(k_mask, lambda: torch.ones((b, context.shape[-2]), device = device).bool())\n",
    "            \n",
    "            q_mask = rearrange(q_mask, 'b i -> b () i ()')\n",
    "            k_mask = rearrange(k_mask, 'b j -> b () () j')\n",
    "            return q_mask * k_mask\n",
    "        else: return None #attn_mask is None if both mask and context_mask are None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "sl = 128\n",
    "d = 64\n",
    "x = torch.randn(bs, sl, d)\n",
    "context = torch.randn(bs, sl-16, d)\n",
    "attn = Attention(d)\n",
    "out = attn(x)\n",
    "assert (bs, sl, d) == out.size()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = attn(x, context)\n",
    "assert (bs, sl, d) == out.size()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test shared_qk\n",
    "bs = 4\n",
    "sl = 128\n",
    "d = 64\n",
    "x = torch.randn(bs, sl, d)\n",
    "context = torch.randn(bs, sl-16, d)\n",
    "attn = Attention(d, shared_qk=True)\n",
    "out = attn(x)\n",
    "assert (bs, sl, d) == out.size()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_msg = \"Causal masking error\"\n",
    "attn = Attention(d, causal=True, dropout=0)\n",
    "x1 = torch.randn(bs, sl, d)\n",
    "out1 = attn(x1)\n",
    "x2 = x1.clone()\n",
    "x2[:, sl//2:, :] = torch.randn(bs, sl//2, d)\n",
    "out2 = attn(x2)\n",
    "# all elements in first half are equal despite second half is defferent\n",
    "assert all_equal(out1[:, :sl//2], out2[:, :sl//2]), e_msg\n",
    "assert not (out1[:, sl//2:] == out2[:, sl//2:]).any(), e_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_msg = \"Masking error\"\n",
    "attn = Attention(d, causal=False, dropout=0)\n",
    "x1 = torch.randn(bs, sl, d)\n",
    "mask = torch.ones(bs, sl)\n",
    "# mask out second half of input\n",
    "mask[:, sl//2:] = 0\n",
    "mask = mask.bool()\n",
    "out1 = attn(x1, mask=mask)\n",
    "x2 = x1.clone()\n",
    "x2[:, sl//2:, :] = torch.randn(bs, sl//2, d)\n",
    "out2 = attn(x2, mask=mask)\n",
    "# all elements are equal, masked values do not effect result\n",
    "assert all_equal(out1[:, :sl//2], out2[:, :sl//2]), e_msg\n",
    "out1 = attn(x1)\n",
    "out2 = attn(x2)\n",
    "assert not (out1[:, :sl//2] == out2[:, :sl//2]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_msg = \"Context masking error\"\n",
    "attn = Attention(d, causal=False, dropout=0)\n",
    "x = torch.randn(bs, sl, d)\n",
    "context = torch.randn(bs, sl, d)\n",
    "context_mask = torch.ones(bs, sl)\n",
    "# mask out second half of context\n",
    "context_mask[:, sl//2:] = 0\n",
    "context_mask = context_mask.bool()\n",
    "out1 = attn(x, context, context_mask=context_mask)\n",
    "context2 = context.clone()\n",
    "context2[:, sl//2:, :] = torch.randn(bs, sl//2, d)\n",
    "out2 = attn(x, context2, context_mask=context_mask)\n",
    "# all elements are equal, masked values do not effect result\n",
    "assert all_equal(out1, out2), e_msg\n",
    "# all output values are different for different context\n",
    "out1 = attn(x, context)\n",
    "out2 = attn(x, context2)\n",
    "assert not (out1 == out2).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check stored attention matrix\n",
    "torch.manual_seed(842)\n",
    "bs = 4\n",
    "sl = 16\n",
    "csl = sl + 16\n",
    "d = 64\n",
    "x = torch.rand(bs, sl, d)\n",
    "context = torch.rand(bs, csl, d)\n",
    "mask = torch.ones(bs, sl)\n",
    "mask[:, -5:] = 0\n",
    "context_mask = torch.ones(bs, csl)\n",
    "context_mask[:, -10:] = 0\n",
    "mask, context_mask = mask.bool(), context_mask.bool()\n",
    "attn = Attention(d, store_attention=True)\n",
    "out = attn(x, context, mask=mask, context_mask=context_mask)\n",
    "attention = attn.attn.attention\n",
    "assert (bs, sl, d) == out.size()\n",
    "assert attention.size() == (bs, attn.attn.n_heads, sl, csl)\n",
    "# zeros for masked keys and \"don't cares\" for masked queries\n",
    "plt.matshow(attention[0,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "#skip\n",
    "# check stored attention matrix\n",
    "torch.manual_seed(842)\n",
    "bs = 4\n",
    "sl = 16\n",
    "d = 64\n",
    "x = torch.rand(bs, sl, d)\n",
    "mask = torch.ones(bs, sl)\n",
    "mask[:, -5:] = 0\n",
    "mask = mask.bool()\n",
    "attn = Attention(d, store_attention=True, causal=True)\n",
    "out = attn(x, mask=mask)\n",
    "attention = attn.attn.attention\n",
    "assert (bs, sl, d) == out.size()\n",
    "assert attention.size() == (bs, attn.attn.n_heads, sl, sl)\n",
    "# zeros for masked keys and \"don't cares\" for masked queries\n",
    "plt.matshow(attention[0,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_attention.ipynb.\n",
      "Converted 03_transformer.ipynb.\n",
      "Converted 04_reformer.ipynb.\n",
      "Converted 05_tokenizers.ipynb.\n",
      "Converted 06_data.ipynb.\n",
      "Converted 07_metrics.ipynb.\n",
      "Converted 08_optimizers.ipynb.\n",
      "Converted 09_tracking.ipynb.\n",
      "Converted 10_config.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchenv]",
   "language": "python",
   "name": "conda-env-torchenv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
